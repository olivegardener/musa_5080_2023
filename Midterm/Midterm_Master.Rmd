---
title: "PPA_Midterm"
author: "Oliver Atwood + Dave Drennan"
date: "2023-10-01"
output: html_document
---

```{r setup, include=FALSE}
rm(list=ls())

knitr::opts_chunk$set(echo = TRUE)

root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

#some of these are repetitive with above - from Intro_to_ML_Pt`
library(ggplot2)
library(units)
library(httr)
library(rgdal)
library(corrplot)
library(tidyverse)
library(dplyr)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
library(lubridate)
library(stargazer)

# Coordinate System
coordinate_system <- 2272

options(scipen = 999)

Sys.setenv(OGR_GEOJSON_MAX_OBJ_SIZE = "1000000")  # Set to a large value

```

### Load studentData
```{r warning=FALSE}
Houses <- st_read("data/studentData.geojson") %>%
  st_transform(crs = coordinate_system) %>% 
    dplyr::select(sale_price, basements, building_code_description, category_code_description, central_air, exterior_condition,
                  fireplaces, garage_spaces, interior_condition, number_of_bathrooms, number_of_bedrooms, number_of_rooms,
                  number_stories, quality_grade, sale_date, total_area, total_livable_area, type_heater, year_built, 
                  building_code_description_new, musaID, geometry) %>% 
    mutate(age = 2023-year_built) %>% 
    dplyr::select(-year_built)

```

## Read wrangled data
```{r, message=FALSE}
##OA Local files
# TreeCanopy <- st_read("/Users/oliveratwood/Box Sync/PPA Midterm/data/TreeCanopy.geojson")
# landuse <- st_read("/Users/oliveratwood/Box Sync/PPA Midterm/data/Land_Use.geojson")%>%
#   st_transform(crs = coordinate_system)

catchments <- st_read("data/School_Catchment/Catchment_ES_2021-22") %>% st_transform(crs = coordinate_system)
Redlined <- st_read("data/redlining.geojson")
Vacant_Lots <- st_read("data/Vacant_Lots.geojson")
Recycling_Diversion_Rate <- st_read("data/Recycling_Diversion_Rate.geojson")
Hospitals <- st_read("data/Hospitals.geojson")
Regional_Rail_Stations <- st_read("data/Regional_Rail_Stations.geojson")
Existing_Trails <- st_read("data/Existing_Trails.geojson")
Traffic_Collisions <- st_read("data/PhillyHealth_Collisions.geojson")
trees <- st_read("data/trees.geojson") %>% mutate(TREE_DBH = as.factor(TREE_DBH))
bike_network <- st_read("data/bike_network.geojson")
parks <- st_read("data/parks.geojson")
uni <- st_read("data/uni.geojson")
neighborhoods <- st_read("data/neighborhoods.geojson")
landcare_lots <- st_read("data/landcare_lots.geojson")
tracts2020 <- st_read("data/tracts2020.geojson")
septa <- st_read("data/septa.geojson")
planning_districts <- st_read("data/Planning_Districts.geojson") %>% st_transform(coordinate_system)
septa_bus <- septa %>% 
  filter(mode == "Bus")
septa_trolley <- septa %>% 
  filter(mode == "Trolley")
septa_highspeed <- septa %>% 
  filter(mode == "Highspeed")

```

### Sample Data (for refining methodolgy)
```{r}
# Sample Data for testing
# n_sample <- round(nrow(Houses) * 0.1)
# Houses <- Houses[sample(nrow(Houses), n_sample), ]
```

### Extract polygon data to points
```{r}
Houses <- Houses %>% 
          st_join(dplyr::select(Recycling_Diversion_Rate, SCORE)) %>% 
          st_join(dplyr::select(neighborhoods, NAME)) %>%
          st_join(dplyr::select(catchments, ES_Name)) %>%
          st_join(dplyr::select(Redlined, holc_grade)) %>%
          st_join(dplyr::select(planning_districts, DIST_NAME)) %>%
          st_join(dplyr::select(tracts2020, MedHHInc, MedRent, HomeOwnRate, PopDensity, PctWhite, PctBach, Car2WorkPct)) %>%
          rename(RecyclingRate = SCORE,
                 Neighborhood = NAME,
                 MedHHInc_ACS = MedHHInc,
                 MedRent_ACS = MedRent,
                 PopDensity_ACS = PopDensity,
                 PctWhite_ACS = PctWhite,
                 PctBach_ACS = PctBach,
                 Car2WorkPct_ACS = Car2WorkPct,
                 dist = DIST_NAME) %>% 
          mutate(PctBach_ACS == PctBach_ACS*100) %>% 
          select(-HomeOwnRate)

```

### Compute min dist to trails and bike network
```{r}
# these are proxy values to speed runs, replace with commented section in final version
Houses$dist2trail <- 5
Houses$dist2bike <- 5
Houses$dist2park <- 5

# ## Trails
# # Compute distances
# distances <- st_distance(Houses, Existing_Trails)
# # Compute the minimum distance for each point to the nearest line
# min_distances <- apply(distances, 1, min)
# # Join the minimum distances to the attribute table of the points
# Houses$dist2trail <- min_distances
# 
# ## Bike Network
# distances <- st_distance(Houses, bike_network)
# min_distances <- apply(distances, 1, min)
# Houses$dist2bike <- min_distances
# 
# # Parks
# distances <- st_distance(Houses, parks)
# min_distances <- apply(distances, 1, min)
# Houses$dist2park <- min_distances

```

### Compute percent canopy cover within 500ft
```{r warning = FALSE}
# # Create buffers around each house
# HouseBuffers <- st_buffer(Houses, dist = (0.25*5280))
# 
# # Initialize an empty vector to store the canopy coverage percent for each house
# CanopyPct100ft <- vector("numeric", length = nrow(Houses))
# 
# # Loop through each house buffer
# for (i in 1:nrow(HouseBuffers)) {
# # Calculate the intersection area between the current house buffer and the tree canopy
# intersection_area <- sum(st_area(st_intersection(HouseBuffers[i, ], TreeCanopy)))
#   
# # Calculate the canopy coverage percent for the current house buffer
# CanopyPct100ft[i] <- (intersection_area / st_area(HouseBuffers[i, ])) * 100}
# 
# # Add the canopy coverage percent values to the Houses data frame
# Houses$CanopyPctQuMi <- CanopyPct100ft

```

### K nearest neighbors
```{r k nearest neighbors, warning=FALSE}
Houses <- Houses %>%
    mutate(hospitals_nn1 = nn_function(st_coordinates(Houses), 
                              st_coordinates(Hospitals), k = 1),
           rr_station_nn1 = nn_function(st_coordinates(Houses), 
                              st_coordinates(Regional_Rail_Stations), k = 1),
           septa_trolley_nn1 = nn_function(st_coordinates(Houses), 
                              st_coordinates(septa_trolley), k = 1),
           septa_bus_nn5 = nn_function(st_coordinates(Houses), 
                              st_coordinates(septa_bus), k = 5), # look into this?
           septa_highspeed_nn1 = nn_function(st_coordinates(Houses), 
                              st_coordinates(septa_highspeed), k = 1),
           collisions_nn3 = nn_function(st_coordinates(Houses), 
                              st_coordinates(Traffic_Collisions), k = 3), #data old, keep?
           unis_nn1 = nn_function(st_coordinates(Houses), 
                              st_coordinates(st_centroid(uni)), k = 1),
           landcare_lots_nn5 = nn_function(st_coordinates(Houses), 
                              st_coordinates(st_centroid(landcare_lots)), k = 5),
           vacant_lots_nn5 = nn_function(st_coordinates(Houses), 
                              st_coordinates(st_centroid(Vacant_Lots)), k = 5)) %>% 
    filter(sale_price != 0)

```


```{r deliverables packages}
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")

```

Deliverables

# Introduction

# Summary Statistics

```{r stargazer table}

# Convert sf object to data frame
Houses_df <- as.data.frame(Houses) %>%
  select(-musaID)

parameters <- names(Houses_df)

# option parameter can be used to set order based on index
stargazer(Houses_df, type = "text", title = "Table 1: Summary Statistics")


```


# Home Price Scatterplots
Example from book for facetwrap scatterplots

```{r scatterplots, fig.width=9, fig.height=3}

st_drop_geometry(Houses) %>% 
  select(sale_price, vacant_lots_nn5, dist2bike, septa_bus_nn5, collisions_nn3) %>%
  filter(sale_price <= quantile(sale_price, 0.9)) %>%
  gather(Variable, Value, -sale_price) %>% 
   ggplot(aes(log(Value), sale_price)) +
     geom_point(size = .01) + geom_smooth(method = "lm", se=F, colour = "#FA7800") +
     facet_wrap(~Variable, ncol = 4, scales = "free") +
     labs(title = "Price as a function of continuous variables") +
     plotTheme()

```

# Map Home Prices

Follow book - map quintile breaks over neighborhoods 
```{r map home prices}

#book used price per square foot
ggplot() +
  geom_sf(data = planning_districts, fill = "grey40") +
  geom_sf(data = Houses, aes(colour = q5(sale_price)), 
          show.legend = "point", size = .01) +
  scale_colour_manual(values = palette5,
                   labels=qBr(Houses,"sale_price"),
                   name="Quintile\nBreaks") +
  labs(title="Sale Price, Philly") +
  mapTheme()


```

# 3 Interesting Maps (bonus for something extra engaging)

```{r heatmap1}
ggplot() + geom_sf(data = neighborhoods, fill = "white") +
  stat_density2d(data = data.frame(st_coordinates(trees)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
  scale_fill_gradient(low = "lightgreen", high = "darkgreen", 
                      breaks=c(0.000000003,0.00000003),
                      labels=c("Minimum","Maximum"), name = "Density") +
  scale_alpha(range = c(0.00, 0.35), guide = FALSE) +
  labs(title = "Weighted Density of Trees, Philly") +
  mapTheme()

```

```{r map2}
ggplot() + geom_sf(data = neighborhoods, fill = "white") +
  stat_density2d(data = data.frame(st_coordinates(Vacant_Lots)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
  scale_fill_gradient(low = "pink", high = "darkred", 
                      breaks=c(0.000000003,0.00000003),
                      labels=c("Minimum","Maximum"), name = "Density") +
  scale_alpha(range = c(0.00, 0.35), guide = FALSE) +
  labs(title = "Density of Vacant Lots, Philly") +
  mapTheme()
```
+ map for distance to bike lanes
```{r map}
ggplot() + geom_sf(data = neighborhoods, fill = "white") +
  stat_density2d(data = data.frame(st_coordinates(bike_network)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
  scale_fill_gradient(low = "lightblue", high = "darkblue", 
                      breaks=c(0.000000003,0.00000003),
                      labels=c("Minimum","Maximum"), name = "Density") +
  scale_alpha(range = c(0.00, 0.35), guide = FALSE) +
  geom_sf(data = bike_network, color = "green", alpha = .3)+
  labs(title = "Density of Bike Network, Philly") +
  mapTheme()

```

Let's try making a model with all of our variables, to start.

```{r model 1}
Houses_Clean <- dplyr::select(Houses, -musaID)

reg1 <- lm(sale_price ~ ., data = select_if(st_drop_geometry(Houses_Clean), is.numeric))
summary(reg1)

```
Let's try narrowing down the variables based on a correlogram
```{r correlation matrix, fig.width=14}
# Select variables of interest and convert them to numeric
vars_of_interest <- select_if(st_drop_geometry(Houses), is.numeric) %>% 
  select(-musaID) %>% 
  na.omit()

ggcorrplot(
  round(cor(vars_of_interest), 2), 
  p.mat = cor_pmat(vars_of_interest),
  colors = c("#FA7800", "white", "#25CB10"),
  type="lower",
  insig = "blank",
  lab = TRUE,  # Ensure labels are shown
  lab_size = 2.5  # Adjust the size of the labels
  ) +  
    labs(title = "Correlation across numeric variables") +
  theme(axis.text = element_text(size = 6)) 

```
From this correlogram, we can see that there are some potentially co-linear variables and variables with low correlation with sale_price. Let's remove these variables and make a model with this smaller set.

```{r model 2}
Houses2 <- Houses_Clean %>% dplyr::select(-number_stories, -age, -PopDensity_ACS, -Car2WorkPct_ACS, -dist2trail, -dist2park, -hospitals_nn1, -rr_station_nn1, -septa_trolley_nn1, -septa_highspeed_nn1, -unis_nn1, -landcare_lots_nn5)

reg2 <- lm(sale_price ~ ., data = select_if(st_drop_geometry(Houses2), is.numeric))
summary(reg2)


coefficients(reg2)
```
Our R-squared variable only decreased by 0.01. Not bad at all, given the number of variables removed. There are a lot of variables in this model that appear to have low significance, let's remove them.


```{r model 3}
Houses3 <- Houses2 %>% dplyr::select(-garage_spaces, -MedHHInc_ACS, -MedRent_ACS, -PctWhite_ACS, -dist2bike, -collisions_nn3, -vacant_lots_nn5)

reg3 <- lm(sale_price ~ ., data = select_if(st_drop_geometry(Houses3), is.numeric))
summary(reg3)

```

```{r model 4}
Houses4 <- Houses3 %>% dplyr::select(-RecyclingRate)
```


We weren't taking into account spatial adjustments - I think the whittling down threw off the original regressions. Following chunk creates a dataset of only variables we care about and includes redlining - was having trouble with the factor level with neighborhoods and catchments.
```{r regression final}

Houses_Clean2 <- Houses_Clean %>%
  mutate(PctBach_ACS = PctBach_ACS*100,
         exterior_condition = replace(Houses_Clean$exterior_condition, is.na(Houses_Clean$exterior_condition), median(Houses_Clean$exterior_condition, na.rm = TRUE)))
       
         
summary(Houses_Clean2)



regression_data <- Houses_Clean %>% dplyr::select(
                                                  sale_price,
                                                  exterior_condition, 
                                                  fireplaces, 
                                                  interior_condition, 
                                                  number_of_bathrooms, 
                                                  number_of_bedrooms, 
                                                  #number_of_rooms, 
                                                  total_area, 
                                                  total_livable_area, 
                                                  PctBach_ACS, 
                                                  septa_bus_nn5, 
                                                  #Neighborhood, 
                                                  #holc_grade,
                                                  dist
                                                  #ES_Name
                                                  ) 

regression <- lm(sale_price ~ ., data = as.data.frame(st_drop_geometry(regression_data)))

summary(regression)


Philly_Data <- regression_data
```

# Table of Results (Training Set)
### remove challenge data, split into training and test sets

```{r regression training set}
inTrain <- createDataPartition(
              y = paste(Philly_Data$dist),
              p = .60, list = FALSE)
Philly_Data.training <- st_drop_geometry(Philly_Data[inTrain,])
Philly_Data.test <- Philly_Data[-inTrain,]  
 
Philly_Data.training <- Philly_Data.training %>%
                                    dplyr::select(sale_price,
                                                  exterior_condition, 
                                                  fireplaces, 
                                                  interior_condition, 
                                                  number_of_bathrooms, 
                                                  number_of_bedrooms, 
                                                  #number_of_rooms, 
                                                  total_area, 
                                                  total_livable_area, 
                                                  PctBach_ACS, 
                                                  septa_bus_nn5, 
                                                  #Neighborhood, 
                                                  dist,
                                                  # Neighborhood, 
                                                  # holc_grade, 
                                                  #ES_Name
                                                  ) 

Philly_Data.test <- Philly_Data.test %>%
                                    dplyr::select(sale_price,
                                                  exterior_condition, 
                                                  fireplaces, 
                                                  interior_condition, 
                                                  number_of_bathrooms, 
                                                  number_of_bedrooms, 
                                                  #number_of_rooms, 
                                                  total_area, 
                                                  total_livable_area, 
                                                  PctBach_ACS, 
                                                  septa_bus_nn5, 
                                                  #Neighborhood, 
                                                  dist,
                                                  # Neighborhood, 
                                                  # holc_grade, 
                                                  #ES_Name
                                                  )

reg.training <- 
  lm(sale_price ~ ., data = as.data.frame(Philly_Data.training))

```

# Table of Goodness of Fit (Test Set)

```{r goodness of fit}

Philly_Data.test <-
  Philly_Data.test %>%
  mutate(Regression = "Regression",
         sale_price.Predict = predict(reg.training, Philly_Data.test),
         sale_price.Error = sale_price.Predict - sale_price,
         sale_price.AbsError = abs(sale_price.Predict - sale_price),
         sale_price.APE = (abs(sale_price.Predict - sale_price)) / sale_price.Predict)%>%
  filter(sale_price < 5000000)  
 
st_drop_geometry(Philly_Data.test) %>%
  select(sale_price.Predict, sale_price.Error, sale_price.AbsError, sale_price.APE) %>%
  kbl()


st_drop_geometry(Philly_Data.test) %>%
  gather(Variable, Value, -Regression, -dist) %>%
  filter(Variable == "sale_price.AbsError" | Variable == "sale_price.APE") %>%
  group_by(Regression, Variable) %>%
    summarize(meanValue = mean(Value, na.rm = T)) %>%
    spread(Variable, meanValue) %>%
    kable()
```


# CV Results

Example from book

```{r cross validation}

fitControl <- trainControl(method = "cv", number = 100)
set.seed(825)

reg.cv <- 
  train(sale_price ~ ., data = st_drop_geometry(Philly_Data.training) %>% 
                                dplyr::select(
                                              sale_price,
                                              exterior_condition, 
                                              fireplaces, 
                                              interior_condition, 
                                              number_of_bathrooms, 
                                              number_of_bedrooms, 
                                              #number_of_rooms, 
                                              total_area, 
                                              total_livable_area, 
                                              PctBach_ACS, 
                                              septa_bus_nn5,
                                              dist
                                              #holc_grade
                                              ),
     method = "lm", trControl = fitControl, na.action = na.pass)

reg.cv

```

# Pred vs Obs Scatterplot

Example from book - edit wording

```{r pred and obs}

Philly_Data.test %>%
  dplyr::select(sale_price.Predict, sale_price, Regression) %>%
    ggplot(aes(sale_price, sale_price.Predict)) +
  geom_point() +
  stat_smooth(aes(sale_price, sale_price), 
             method = "lm", se = FALSE, size = 1, colour="#FA7800") + 
  stat_smooth(aes(sale_price.Predict, sale_price), 
              method = "lm", se = FALSE, size = 1, colour="#25CB10") +
  labs(title="Predicted sale price as a function of observed price",
       subtitle="Orange line represents a perfect prediction; Green line represents prediction") +
  plotTheme()

```

# Residuals Map w/ Moran's I



need to make sure there's no NA data to run this correctly
```{r moran map}

coords.test <-  st_coordinates(Philly_Data.test) 

neighborList.test <- knn2nb(knearneigh(coords.test, 5))

spatialWeights.test <- nb2listw(neighborList.test, style="W")
 
Philly_Data.test %>% 
  mutate(lagPriceError = lag.listw(spatialWeights.test, sale_price.Error)) %>%
  ggplot()+
  geom_point(aes(x =lagPriceError, y =sale_price.Error))


moranTest <- moran.mc(Philly_Data.test$sale_price.Error, 
                      spatialWeights.test, nsim = 999)



```
# Predicted Map (Test Set)

Is this kind of map right?

```{r pred map}

ggplot() +
  geom_sf(data = neighborhoods, fill = "grey40") +
  geom_sf(data = Philly_Data.test, aes(colour = q5(sale_price)), 
          show.legend = "point", size = .01) +
  scale_colour_manual(values = palette5,
                   labels=qBr(Philly_Data.test,"sale_price"),
                   name="Quintile\nBreaks") +
  labs(title="Sale Price, Philly") +
  mapTheme()

```


# MAPE map by neighborhood

Example from book

```{r mape map}
# Spatial join
Philly_Data.test <- st_join(Philly_Data.test, neighborhoods, join = st_within)

Philly_Data.test <- Philly_Data.test %>% 
  rename(neighborhood = NAME)

# Grouping and summarization
mean_MAPE_by_neighborhood <- st_drop_geometry(Philly_Data.test) %>%
  group_by(neighborhood) %>%
  summarise(mean.MAPE = mean(sale_price.APE, na.rm = TRUE)) %>%
  ungroup()

# Ensure that "neighborhood" in mean_MAPE_by_neighborhood matches the identifier in neighborhoods
neighborhoods <- neighborhoods %>%
  left_join(mean_MAPE_by_neighborhood, by = c("NAME" = "neighborhood"))


MAPE.Map <- ggplot() + 
  geom_sf(data = neighborhoods, aes(fill = mean.MAPE)) +
  scale_fill_gradient(low = palette5[1], high = palette5[5],
                        name = "MAPE") +
  labs(title = "Mean test set MAPE by neighborhood") +
  mapTheme()

MAPE.Map






```

# Scatterplot - MAPE by neighborhood mean price



# Split by Census Groups

Example from book

```{r tracts}
tracts17 <- 
  get_acs(geography = "tract", variables = c("B01001_001E","B01001A_001E","B06011_001"), 
          year = 2017, state="PA", county="Philadelphia", geometry=T, output = "wide") %>%
  st_transform(crs=2272)  %>%
  rename(TotalPop = B01001_001E,
         NumberWhites = B01001A_001E,
         Median_Income = B06011_001E) %>%
  mutate(percentWhite = NumberWhites / TotalPop,
         raceContext = ifelse(percentWhite > .5, "Majority White", "Majority Non-White"),
         incomeContext = ifelse(Median_Income > 32322, "High Income", "Low Income"))

grid.arrange(ncol = 2,
  ggplot() + geom_sf(data = na.omit(tracts17), aes(fill = raceContext)) +
    scale_fill_manual(values = c("#25CB10", "#FA7800"), name="Race Context") +
    labs(title = "Race Context") +
    mapTheme() + theme(legend.position="bottom"), 
  ggplot() + geom_sf(data = na.omit(tracts17), aes(fill = incomeContext)) +
    scale_fill_manual(values = c("#25CB10", "#FA7800"), name="Income Context") +
    labs(title = "Income Context") +
    mapTheme() + theme(legend.position="bottom"))

#MAPE for both regressions by race
st_join(Philly_Data.test, tracts17) %>% 
  group_by(Regression, raceContext) %>%
  summarize(mean.MAPE = scales::percent(mean(sale_price.APE, na.rm = T))) %>%
  st_drop_geometry() %>%
  spread(raceContext, mean.MAPE) %>%
  kable(caption = "Test set MAPE by neighborhood racial context")

#MAPE for both regressions by income
st_join(Philly_Data.test, tracts17) %>% 
  filter(!is.na(incomeContext)) %>%
  group_by(Regression, incomeContext) %>%
  summarize(mean.MAPE = scales::percent(mean(sale_price.APE, na.rm = T))) %>%
  st_drop_geometry() %>%
  spread(incomeContext, mean.MAPE) %>%
  kable(caption = "Test set MAPE by neighborhood income context")

```

# Discussion
## Accuracy

## Generalizability

# Conclusion and Recommendation

