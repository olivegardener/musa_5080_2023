---
title: "Predicting Single Family Home Prices in Philadelphia, PA"
author: "Oliver Atwood + Dave Drennan"
date: "2023-10-11"
output: 
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
    number_sections: yes
editor_options: 
  markdown: 
    wrap: 72
---

```{r packages, include=FALSE}
rm(list=ls())

knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

#some of these are repetitive with above - from Intro_to_ML_Pt`
library(ggplot2)
library(units)
library(httr)
library(rgdal)
library(corrplot)
library(tidyverse)
library(tidycensus)
library(dplyr)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
library(lubridate)
library(stargazer)
library(purrr)
library(tigris)
library(extrafont)
library(gtsummary)
library(vtable)
library(patchwork)


# Coordinate System
coordinate_system <- 2272

options(scipen = 999)

Sys.setenv(OGR_GEOJSON_MAX_OBJ_SIZE = "1000000")  # Set to a large value

palette_sequential <- c("#ffffb2", "#fecc5c", "#fd8d3c", "#f03b20", "#bd0026")
palette_diverging <- c("#e66101", "#fdb863", "#f7f7f7", "#b2abd2", "#5e3c99")
palette_three <- c("#e66101", "#f7f7f7", "#5e3c99")

```
# Introduction

To support Zillow’s goal of more accurate housing market predictions, the focus of our analysis is to predict single family housing prices in Philadelphia, PA through the use of local data sources. This task is challenging due to the multifaceted nature of the housing market. House prices are influenced by both internal and external characteristics and are subject to the unruly forces of market dynamics, which add a layer of turbulence to the data. Not everyone is a rational actor...

However, accurately estimating home values is hugely important because the cost of housing plays a critical role in the lives of residents. The value of a home is important to its owner because if overestimated, it may place undue burden on the homeowner through higher property taxes. On the other hand, underestimation of housing values leads to the devaluation of one of the largest investments in most people’s lives. Additionally, it's important that our customers are confident in the information we provide them given our status as a leader in the real estate business. As a result, it is critical to estimate the fair market value of houses by leveraging a wide variety of variables that influence home value.

So why is this a difficult exercise? It is impossible to account for every factor in a model of housing price. Additionally, there is the risk of involving too many factors in the model, which results in estimates that are exceptionally accurate for the available data we already have, but bad for data outside of the model. This is known as “overfitting” a model, which results in poor generalizability.

The overall modeling strategy employed in this analysis involves the collection of a range of internal and external characteristics of individual houses, which are then used in statistical analyses to estimate the value of individual Philadelphia homes in the data set. 

The starting point for this model was assessment data from the City of Philadelphia, which included sale prices and a variety of other internal characteristics for every house in Philadelphia. We also included a range of external data with characteristics of the broader urban landscape. Using a number of statistical methods, we summarized these characteristics in relation to each individual house in the assessment data. Once these internal and external characteristics were compiled into a single data set, we explored relationships between the various factors and sale price, narrowing them down the ones with the most impact for predicting home values.

We then split the data into two groups, a “training set” and a “test set.” The training set was used to develop a model for predicting sale prices for homes in Philadelphia using on our chosen factors. The resulting model was then used to predict sale prices of houses in the test set, and the actual and predicted sale prices were compared.

When we used our model to predict sale prices across Philadelphia, it performed relatively well for areas with predominantly higher income, white populations. However, it struggled more in areas with majority non-white and/or lower income populations.

# Data

Data used in this model were gathered from a variety of sources and joined into a single data set. We used this data to build a linear regression model for predicting home sale price. To supplement the original data set provided for this project - housing assessment data for Philadelphia - we used a mix of API calls and direct downloads to gather the data.

API calls were used to download most data gathered for this analysis, including: 

* Demographic data from the American Community Survey (ACS), 
* Data on the location of highways from OpenStreetMap (OSM),
* Data on the trees, bike network, land use, parks, universities, neighborhoods, subway stops, community landcare lots, landcare maintenance lots, redlining, and food access in Philadelphia from the city’s ArcGIS REST data server.

The remainder of the data was previously downloaded from Open Data Philly for use in a separate project and was imported as a geodatabase. These data sets included information for vacant lots, recycling diversion rates, hospitals, regional rail stations, trail networks, trolley stops, and traffic collisions. Data was then merged as needed, such as combining trolley stops, subway stops and regional rail stations together to form a “rail station” data set.

A cleaned version of the housing assessment data for Philadelphia was created, containing only the variables we felt were most influential on single family home prices:
 
 * musaID and toPredict,
 * Sale price, 
 * Interior condition and exterior condition,
 * Fireplaces, 
 * Number of bathrooms and number of bedrooms, 
 * Total area and total livable area,
 * Year built, to calculate the age of the home,
 * Geometry, for mapping purposes

The external data were then integrated into the cleaned version of the housing assessment data for Philadelphia using a variety of methods: 
 
 * Information from a given area, such as data from Census tracts, was added to individual points to contextualize the areas around a  home,
 * The distance from each house to its nearest park was calculated ,
 * Tree totals were incorporated by counting all trees within 500 feet of each house,
 * Rail stops and vacant lots were incorporated through a ‘K nearest neighbors’ function, which averaged the distance to the nearest 1 and 3 stops and lots, respectively, 
 * We filtered out data with the top 1% of sale prices to limit extreme outliers influencing our model.

All incomplete variable fields were then calculated as the median value from the full data set for each variable. The joined data was  narrowed down by eliminating variables that were deemed too similar to each other through statistical methods, as well as variables that had a weak relationship with the sale price of homes.


## Loading Data

```{r load data, results = "hide", fig.show='hide'}
# provided data

student_data <- st_read("data/studentData.geojson") %>% 
  st_transform(crs = coordinate_system) 

# wrangled data

philly_outline <- counties(state = "PA") %>% 
  filter(NAME == "Philadelphia") %>% 
  st_transform(crs = coordinate_system) %>% 
  select(NAME, geometry)

tracts2020 <- st_read("data/tracts2020.geojson") %>% 
  st_transform(crs = coordinate_system)

planning_districts <- st_read("data/Planning_Districts.geojson") %>% 
  st_transform(coordinate_system)

neighborhoods <- st_read("data/neighborhoods.geojson")

redlining <- st_read("data/redlining.geojson") %>% 
  st_transform(crs = coordinate_system) %>%
  mutate(
    holc_grade_val = case_when(
      holc_grade == "Commercial" ~ "0",
      holc_grade == "A" ~ "1",
      holc_grade == "B" ~ "2",
      holc_grade == "C" ~ "3",
      holc_grade == "D" ~ "4",
      )
  )

parks <- st_read("data/parks.geojson") %>% 
  st_transform(crs = coordinate_system)

vacant_lots <- st_read("data/Vacant_Lots.geojson") %>% 
  st_transform(crs = coordinate_system)

trees <- st_read("data/trees.geojson") %>%
  na.omit() %>%
  st_as_sf(coords = c("LOC_X", "LOC_Y"), crs = "EPSG:4326") %>%
  st_transform(crs = coordinate_system) %>% 
  dplyr::select(-TREE_NAME, -TREE_DBH, -YEAR)

septa <- st_read("data/septa.geojson") %>% 
  st_transform(crs = coordinate_system)
light_rail <- septa %>% 
  st_intersection(philly_outline, septa) %>%
  filter(
    (mode == "Highspeed" | mode == "Trolley"), 
    (directionn == "Northbound" | directionn == "Eastbound")
    )

food_access <- st_read("data/NeighborhoodFoodRetail.geojson") %>% 
  st_transform(crs = coordinate_system)

regional_rail <- st_read("data/Regional_Rail_Stations.geojson") %>% 
  st_transform(crs = coordinate_system) %>% 
  st_intersection(philly_outline, regional_rail)

rail_stops <- st_join(light_rail, regional_rail)

```

### Feature Engineering

```{r feature engineering}

# extract polygon data to points

model_data <- student_data %>% 
  dplyr::select(musaID, toPredict, sale_price, exterior_condition, fireplaces, interior_condition, number_of_bathrooms, number_of_bedrooms,
                  total_area, total_livable_area, year_built, geometry) %>% 
  mutate(age = 2023-year_built) %>% 
  dplyr::select(-year_built)

model_data <- model_data %>% 
          st_join(dplyr::select(redlining, holc_grade_val)) %>%
          st_join(dplyr::select(food_access, TOTAL_HPSS, TOTAL_LPSS)) %>% #HPSS is high produce supply store, LPSS is low produce
          st_join(dplyr::select(tracts2020, MedHHInc, PctWhite, PctBach)) %>%
          rename(
                 MedHHInc_ACS = MedHHInc,
                 PctWhite_ACS = PctWhite,
                 PctBach_ACS = PctBach,
                 quality_produce_access = TOTAL_HPSS,
                 low_produce_access = TOTAL_LPSS)%>% 
          mutate(PctWhite_ACS = PctWhite_ACS*100,
                 PctBach_ACS = PctBach_ACS*100,
                 holc_grade_val = as.numeric(holc_grade_val)
                 )

# min distance to parks

distances <- st_distance(model_data, parks)
min_distances <- apply(distances, 1, min)
model_data$dist2park <- min_distances

# K nearest neighbors

model_data <- model_data %>%
    mutate(
      rail_stop_nn1 = nn_function(st_coordinates(model_data), 
                                     st_coordinates(st_centroid(rail_stops)), 
                                     k = 1),
      vacant_lots_nn3 = nn_function(st_coordinates(model_data), 
                                    st_coordinates(st_centroid(vacant_lots)), 
                                    k = 3),
      )

# tree count buffers

model_data$tree.count.buffer <- model_data %>% 
    st_buffer(500) %>% 
    aggregate(mutate(trees, counter = 1),., sum) %>%
    pull(counter)

# imputing missing values

model_data <- model_data %>%
  mutate(
    exterior_condition = ifelse(is.na(exterior_condition), median(exterior_condition, na.rm = TRUE), exterior_condition),
    interior_condition = ifelse(is.na(interior_condition), median(interior_condition, na.rm = TRUE), interior_condition),
    number_of_bathrooms = ifelse(is.na(number_of_bathrooms), median(number_of_bathrooms, na.rm = TRUE), number_of_bathrooms),
    number_of_bedrooms = ifelse(is.na(number_of_bedrooms), median(number_of_bedrooms, na.rm = TRUE), number_of_bedrooms),
    fireplaces = ifelse(is.na(fireplaces), median(fireplaces, na.rm = TRUE), fireplaces),
    quality_produce_access = ifelse(is.na(quality_produce_access), median(quality_produce_access, na.rm = TRUE), quality_produce_access),
    low_produce_access = ifelse(is.na(low_produce_access), median(low_produce_access, na.rm = TRUE), low_produce_access),
    MedHHInc_ACS = ifelse(is.na(MedHHInc_ACS), median(MedHHInc_ACS, na.rm = TRUE), MedHHInc_ACS),
    PctWhite_ACS = ifelse(is.na(PctWhite_ACS), median(PctWhite_ACS, na.rm = TRUE), PctWhite_ACS),
    total_area = ifelse(is.na(total_area), median(total_area, na.rm = TRUE), total_area),
    tree.count.buffer = ifelse(is.na(tree.count.buffer), median(tree.count.buffer, na.rm = TRUE), tree.count.buffer),
    holc_grade_val = ifelse(is.na(holc_grade_val), median(holc_grade_val, na.rm = TRUE), holc_grade_val),
    age = ifelse(is.na(age), median(age, na.rm = TRUE), age),
    age = ifelse(age<0, 0, age),
    exterior_condition = as.integer(exterior_condition),
    number_of_bathrooms = as.integer(number_of_bathrooms),
    holc_grade_val = as.integer(holc_grade_val),
    tree.count.buffer = as.integer(tree.count.buffer)) %>%
    filter(sale_price < quantile(sale_price, 0.99))


model_data <- model_data %>%
  st_join(dplyr::select(neighborhoods, NAME))  %>%
  rename(neighborhood = NAME) %>%
  mutate(neighborhood = as.factor(neighborhood))


```

## Summary Statistics

```{r summtable table}


model_data_table <- model_data %>%
  select(-musaID, -toPredict)


sumtable(model_data_table, out = "kable") %>%
  kable_styling(full_width = TRUE) %>%
  scroll_box(width = "100%", height = "450px", fixed_thead = TRUE) 
```

## Correlation matrix
```{r correlation matrix}
# Select variables of interest and convert them to numeric
vars_of_interest <- select_if(st_drop_geometry(model_data), is.numeric) %>% 
  select(-musaID) %>% 
  na.omit()

ggcorrplot(
  round(cor(vars_of_interest), 2), 
  p.mat = cor_pmat(vars_of_interest),
  colors = palette_three,
  type="lower",
  insig = "blank",
  lab = TRUE,  # Ensure labels are shown
  lab_size = 1.5  # Adjust the size of the labels
  ) +  
    labs(title = "Correlation Across Numeric Variables") +
  theme(axis.text = element_text(size = 4)) 

```

This correlation matrix shows the relationship between variables in the model - values closer 1 or -1 mean that those two variables are similar in their predictive power on sale price - we used correlation plots to trim variables that had this collinearity of .8 or higher.

## Home Price Correlation Scatterplots

```{r scatterplots, fig.width=10, fig.height=10}

st_drop_geometry(model_data) %>% 
  select(sale_price, vacant_lots_nn3, dist2park, quality_produce_access, tree.count.buffer) %>%
  gather(Variable, Value, -sale_price) %>% 
   ggplot(aes(Value, sale_price)) +
     geom_point(size = .01) + geom_smooth(method = "lm", se=F, colour = "#FA7800") +
     facet_wrap(~Variable, ncol = 2, scales = "free") +
     labs(title = "Price as a function of continuous variables") +
     plotTheme()

```

These scatter plots show the relationship between four of our external variables and sale price. There is a slight negative correlation between distance to park and sale price, meaning that generally speaking, the closer a house is to a park, the higher its sale price. For tree.count.buffer, vacant_lots_nn3, and quality_produce_access, these scatter plots show a positive correlation with sale_price, meaning that in general the more trees near a given house, the farther it is from the nearest three vacant lots, and the more options for quality produce available nearby, the higher a house's expected sale price.

## Map of Home Prices

```{r sale price map}
salepricemap <- ggplot() +
  geom_sf(data = neighborhoods, fill = "white", color = "grey70") +
  geom_sf(data = model_data, 
          aes(colour = sale_price), 
          show.legend = "point", size = .001) +
  scale_colour_gradientn(colors = palette_sequential,
                         name="Sale Price",
                         labels = scales::label_number(scale = 1),
                         guide = guide_colourbar(title.position = "top", title.hjust = 0.5)) +
  labs(title="Single Family Home Sale Prices") +
  mapTheme()

salepricemap

```

This map shows single family home sale prices from the provided assessment data. More expensive homes appear to cluster around Center City, just west of Center City, and in the northwestern part of the city.

## Maps of Independent Variables

### Tree Density
```{r map1}

ggplot() + geom_sf(data = neighborhoods, fill = "white", color = "grey70") +
  stat_density2d(data = data.frame(st_coordinates(trees)), 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
  scale_fill_gradient(low = "lightgreen", high = "darkgreen",
                      name = "Density") +
  scale_alpha(range = c(0.00, 0.35), guide = FALSE) +
  labs(title = "Density of Tree Locations") +
  mapTheme()

```

This map shows the density of individual trees - the most densely wooded areas are generally closer to Center City, near the clusters of high-priced homes shown in the previous figure. One limitation with this data set is that certain large parks in the city do not have their trees counted by Philadelphia Parks and Recreation, who provides the information for this data set.

### High Quality Produce Access
```{r map2}
ggplot() + geom_sf(data = food_access, aes(fill = as.numeric(TOTAL_HPSS)), color = "grey70") +
  scale_fill_gradient(low = "lavender", high = "purple", name = "Store Count")+
  labs(title = "High Quality Produce Access by Store Count",
       subtitle = "Data provided per block group") +
  mapTheme()

```

High quality produce access shows which areas of the city have more stores that are considered to have a high supply of fresh produce, which is used as a qualifier for healthy food access. Block groups with these stores also appear to cluster around Center City.

### Vacant Lot Density
```{r map3}
# Extracting centroids and converting to data.frame
centroids <- st_centroid(vacant_lots)
centroids_df <- data.frame(st_coordinates(centroids))

ggplot() + geom_sf(data = neighborhoods, fill = "white", color = "grey70") +
  stat_density2d(data = centroids_df, 
                 aes(X, Y, fill = ..level.., alpha = ..level..),
                 size = 0.01, bins = 40, geom = 'polygon') +
  scale_fill_gradient(low = "pink", high = "red",
                      name = "Density") +
  scale_alpha(range = c(0.00, 0.35), guide = FALSE) +
  labs(title = "Density of Vacant Lot Locations") +
  mapTheme()
```

This heat map shows areas with high numbers of vacant lots - vacant lots appear concentrated in the northern and western parts of the city, just outside of the areas that showed clusters of high sale prices.

# Methods

After compiling our data and developing features that we believed were predictors for sale price, we conducted a series of statistical analyses to test the accuracy of our prediction. This model uses linear regression, which allowed us to examine the individual impact of each predictor on the sale price of a home in the Philly data set when holding all other predictors equal. 

We split our data into two random groups for a training set and a test set - doing so allowed us to create a sale price prediction model using the training data to predict on the test data. This split let us use our model on houses with known sale prices, but with combinations of predictor variables that the model had not necessarily encountered before. We then compared the sale price predictions in the test data to the actual sale prices and analyzed the difference between our predictions and reality.

Additional statistical methods were then used to compare our results and check if our testing data was representative of the city as a whole:
 
 * We calculated the absolute error and the absolute percent error (APE), which are key figures that show us how much our predictions differ from actual sales prices - the means of each figure were also calculated to show us how well our model performed across different areas of the city and Philadelphia as a whole.
 * We checked if the random group assigned to the test data gave us similar results to other randomly assigned test sets through cross validation - this process let us confirm that our test data didn’t wildly differ from what would be expected in the rest of the city.
 * We compared how much the prediction errors for an individual house differed with neighboring houses’ prediction errors and examined if these sale price errors showed clustering, which would highlight the need for better spatial solutions to accurately predict home prices.

Through the mean absolute percent error (MAPE), we saw which neighborhoods our model predicted accurately, with a lower score meaning that the model was more accurate. We also used MAPE to examine the generalizability of our model with different demographics to see how our model performed in different contexts - in this case, low income versus high income neighborhoods and majority white versus majority non-white neighborhoods.

# Results

## Table of Results (Training Data)
```{r regression partition and summary results}

Philly_Data <- model_data %>%
  filter(toPredict == "MODELLING",
         age < 500) %>%
  dplyr::select(-toPredict,)

# partition
set.seed(123)
inTrain <- createDataPartition(
              y = paste(Philly_Data$neighborhood),
              p = .60, list = FALSE)
Philly_Data.training <- st_drop_geometry(Philly_Data[inTrain,]) %>%
  dplyr::select(-musaID)
Philly_Data.test <- Philly_Data[-inTrain,] %>%
  dplyr::select(-musaID) 
 
reg.training <- 
  lm(sale_price ~ ., data = as.data.frame(Philly_Data.training)) 

```

```{r regression results}

summ(reg.training)

```

This table shows our regression model results, including how well our model fits the data and the significance and impact of each individual variable on sales price when all other predictors are held equal: 

 * The adjusted R-squared tells us that 76% of the variability in sales price is explained by our model. On face value, this relatively high percentage means our model fits the data well, but adjusted R-squared alone doesn't tell us if this model is accurate - as shown later in this report, our chosen variables may be biased towards certain demographic and income contexts. We used adjusted R-squared instead of the non-adjusted R-squared value because it's a better representation of model fit when there is a high number of variables in the model. 

 * The "Est." column shows us how much each variable impacts sales price when all other variables are held equal, with the "p" column indicating to us whether that variable is considered statistically significant within the context of the model. Most of our chosen variables and many of the individual neighborhoods are significant in their impacts on sale price with p values of less than 0.05. Variables are measured in different ways - factors like the condition represent codes assigned by the City, where a 1 represents the best condition and each additional value means the house is in worse condition. Other variables like total livable area show the impact of one additional square foot on the sale price - the estimate indicates that price predictions increase by \$132 for every added square foot.

## Table of Goodness of Fit (Test Data)
```{r goodness of fit}


Philly_Data.test <-
  Philly_Data.test %>%
  mutate(sale_price.Predict = predict(reg.training, Philly_Data.test),
         sale_price.Error = sale_price.Predict - sale_price,
         sale_price.AbsError = abs(sale_price.Predict - sale_price),
         sale_price.APE = (abs(sale_price.Predict - sale_price) / sale_price))
 
# st_drop_geometry(Philly_Data.test) %>%
#   select(sale_price.Predict, sale_price.Error, sale_price.AbsError, sale_price.APE) %>%
#   kbl()

st_drop_geometry(Philly_Data.test) %>%
  gather(Variable, Value, -neighborhood) %>%
  filter(Variable == "sale_price.AbsError" | Variable == "sale_price.APE") %>%
  group_by(Variable) %>%
    summarize(meanValue = mean(Value, na.rm = T)) %>%
    spread(Variable, meanValue) %>% kbl(col.names = c('Sale Price MAE', 'Sale Price MAPE'), digits = 3, format.args = list(big.mark = ",")) %>% kable_styling(full_width = FALSE)

```

The sale price mean absolute error (MAE) and sale price mean absolute percent error (MAPE) show us how much the average amount that our predictions differ from the actual sale prices for houses in the testing set. On average, our predictions are nearly \$60,000 higher or lower than the actual sale price for a home, representing around a 36% difference.  

## Cross Validation Results

```{r cross validation}

fitControl <- trainControl(method = "cv", number = 100)
set.seed(825)

reg.cv <- 
  train(sale_price ~ ., data = st_drop_geometry(Philly_Data.training),
     method = "lm", trControl = fitControl, na.action = na.pass)

SDMAE <- reg.cv$results[7]
CVMAE <- reg.cv$results[4]

CVresults <- cbind(CVMAE, SDMAE)

kbl(CVresults, col.names = c('CV Test MAE', 'CV Test MAE Standard Deviation'), digits = 2) %>% kable_styling(full_width = FALSE)
```

The process of cross-validating the results of our test set is conducted by generating the mean absolute errors of 100 groups of training data, which allows us to confirm if the MAE and MAPE from our test data is expected from our model or outside of the norm as a result of taking a random sample of the data for training. 

 * The table above shows that our test data MAE of about \$60,000 is nearly equal to the average MAE generated by our cross validation test, which has a standard deviation of about \$5,000.



```{CV histogram}
plot1 <- reg.cv$resample

ggplot()+
  geom_histogram(data=plot1, aes(x = MAE))

```

Plotting the 100 cross validation mean absolute errors shows the data centered around the overall mean of about \$60,000 and highlights how test data MAEs are likely to range between about \$50,000 and \$70,000 - about two standard deviations in either direction from the mean.  

## Predicted vs Observed Scatterplot

```{r pred and obs plot}

Philly_Data.test %>%
  dplyr::select(sale_price.Predict, sale_price) %>%
    ggplot(aes(sale_price, sale_price.Predict)) +
  geom_point() +
  stat_smooth(aes(sale_price.Predict, sale_price), 
              method = "lm", se = FALSE, size = 1, colour="#25CB10") +
  stat_smooth(aes(sale_price, sale_price), 
             method = "lm", se = FALSE, size = 1, colour="#FA7800") + 
  labs(title="Predicted Sale Price as a Function of Observed Price",
       subtitle="Orange line represents a perfect prediction; Green line represents prediction") +
  plotTheme()

```

Plotting the predicted sale price as a function of actual sale price and adding lines that best fit the data show us that our predictions track relatively close to what sale price should be. The green line, which represents our predictions, appears to be just below the minimum and just above the maximum of the perfect prediction line in orange - these differences indicate that our model overvalues lower-priced homes and undervalues more expensive homes. However, the previous figures for MAPE told us that our predictions differed from the actual sale price by about 36% on average. As highlighted in later figures, we likely predict many neighborhoods relatively well and some neighborhoods very poorly.

## Residuals and Moran's I Test

### Residuals Map
```{r residuals plot}

ggplot() +
  geom_sf(data = neighborhoods, fill = "white", color = "grey70" ) +
  geom_sf(data = Philly_Data.test, aes(colour = q5(sale_price.Error)), 
          show.legend = "point", size = .6, alpha = .5) +
  scale_colour_manual(values = palette_diverging,
                   labels=qBr(Philly_Data.test,"sale_price.Error"),
                   name="Quintile\nBreaks") +
  labs(title="Difference Between Actual and Predicted Sale Price") +
  mapTheme()

```

By plotting the difference of the actual and predicted sale price of a particular home, known as the residual, we can see that our model both over- and underestimates sale prices in nearly every neighborhood, sometimes by wide margins. Price differences are plotted by quintile, which reveals that are model severely overestimates the sale price for certain houses by as much as over \$250,000 more than they actually sold for.

### Moran's I Plot
```{r moran}

coords.test <-  st_coordinates(Philly_Data.test)

neighborList.test <- knn2nb(knearneigh(coords.test, 5))

spatialWeights.test <- nb2listw(neighborList.test, style="W")

moranTest <- moran.mc(Philly_Data.test$sale_price.Error,
                      spatialWeights.test, nsim = 999)


ggplot(as.data.frame(moranTest$res[c(1:999)]), aes(moranTest$res[c(1:999)])) +
  geom_histogram(binwidth = 0.01) +
  geom_vline(aes(xintercept = moranTest$statistic), colour = "#FA7800",size=1) +
  scale_x_continuous(limits = c(-1, 1)) +
  labs(title="Observed and Permuted Moran's I",
       subtitle= "Observed Moran's I in orange",
       x="Moran's I",
       y="Count") +
  plotTheme()

```

Conducting the Moran's I test lets us see how clustered our data is - in other words, is the difference between the actual and predicted sale price of a particular home similar to other homes neighboring it? This test creates simulations of the test data by shuffling the results of differences to be randomly distributed across the city, plotting the results of the test as a histogram and then comparing it the actual observation of Moran's I in out test data. Our test result of Moran's I tells us that differences do cluster based on geography.

### Spatial Lag in Errors
```{r spatial lag in errors map}

Philly_Data.test %>%
  mutate(lagPriceError = lag.listw(spatialWeights.test, sale_price.Error)) %>%
  ggplot()+
  geom_point(aes(x =lagPriceError, y =sale_price.Error))+
  stat_smooth(aes(lagPriceError, sale_price.Error), 
             method = "lm", se = FALSE, size = 1, colour="#FA7800") +
  labs(title = "Spatial Lag in Errors",
       subtitle = "Orange line represents relationship between variables")
```

The spatial lag in errors plot compares a house's sale price error to its neighbors - the line shows that the relationship is positive, further reinforcing that there is clustering of sale price prediction errors in our test data.

## Predicted Sales Prices Map

```{r pred map}

# Ensure that 'Philly_Data.challenge' only contains the observations you want to predict
Philly_Data.challenge <- model_data

# Generate predictions only for 'Philly_Data.challenge'
Philly_Data.challenge <- Philly_Data.challenge %>%
  mutate(sale_price_prediction = predict(reg.training, .))

# Determine global limits
global_min <- min(min(model_data$sale_price), min(Philly_Data.challenge$sale_price_prediction))
global_max <- max(max(model_data$sale_price), max(Philly_Data.challenge$sale_price_prediction))

# ggplot salepricemap
salepricemap <- ggplot() +
  geom_sf(data = neighborhoods, fill = "white") +
  geom_sf(data = model_data %>% filter(sale_price < quantile(sale_price, 0.99)),
          aes(colour = sale_price),
          show.legend = "point", size = .001) +
  scale_colour_gradientn(colors = palette_sequential,
                         name="Sale Price",
                         labels = scales::label_number(scale = 1),
                         guide = guide_colourbar(title.position = "top", title.hjust = 0.5),
                         limits = c(global_min, global_max)) +  # Set limits
  labs(title="Single Family Home Sale Price") +
  mapTheme()

# ggplot predictedsalepricemap
predictedsalepricemap <- ggplot() +
  geom_sf(data = neighborhoods, fill = "white") +
  geom_sf(data = Philly_Data.challenge, aes(colour = sale_price_prediction),
          show.legend = "point", size = .001) +
  scale_colour_gradientn(colors = palette_sequential,
                         name="Predicted \nSale Price",
                         labels = scales::label_number(scale = 1),
                         guide = guide_colourbar(title.position = "top", title.hjust = 0.5),
                         limits = c(global_min, global_max)) +  # Set limits
  labs(title="Single Family Home \nPredicted Sale Price") +
  mapTheme()

#Arrange the plots side by side
salepricemap + predictedsalepricemap

#export sales price predictions for challenge data to csv
Philly_Data.challenge.csv <- st_drop_geometry(Philly_Data.challenge) %>%
  filter(toPredict == "CHALLENGE") %>%
  dplyr::select(musaID, sale_price_prediction) %>%
  mutate(teamName = "House It Going")

write.csv(Philly_Data.challenge.csv, "HouseItGoing.csv", row.names = FALSE)

```

Mapping the predicted sale prices side by side with the actual sale prices can let us compare what our model predicts home prices to be versus reality. The maps appear to be subtly different, with a few more areas that look darker or lighter on the prediction map compared to the actual sale price map - this reinforces how our model slightly over-predicts sale price in certain areas and severely under-predicts in others. Given the sheer volume of observations in our data set, it is difficult to highlight specific points to compare in a city-wide map.  

## Mean Absolute Percent Error by Neighborhood Map

```{r mape map}
# Spatial join
Philly_Data.test <- st_join(Philly_Data.test, neighborhoods, join = st_within)

# Grouping and summarization
mean_MAPE_by_neighborhood <- st_drop_geometry(Philly_Data.test) %>%
  group_by(neighborhood) %>%
  summarise(mean.MAPE = mean(sale_price.APE, na.rm = TRUE)) %>%
  ungroup()

neighborhoods <- neighborhoods %>%
  left_join(mean_MAPE_by_neighborhood, by = c("NAME" = "neighborhood"))


MAPE.Map <- ggplot() + 
  geom_sf(data = neighborhoods, aes(fill = mean.MAPE)) +
  scale_fill_gradient(low = "lavender", high = "#5e3c99",
                        name = "MAPE") +
  labs(title = "Mean test set MAPE by neighborhood") +
  mapTheme()

MAPE.Map

```

Mapping our MAPE by neighborhood shows that the model is okay at predicting across much of the city - however, errors cluster much higher in one neighborhood in particular without a clear reason for why. One possibility is a lack of observations in our training data for that neighborhood relative to others, which would lead our model to struggle with predictions in that neighborhood and skew our results. The variable we chose may also not predict well in the context of that neighborhood.

```{r house count}
HouseCount_by_neighborhood <- st_drop_geometry(Philly_Data.training) %>%
  group_by(neighborhood) %>%
  summarise(HouseCount = n()) %>% 
  ungroup()

neighborhoods <- neighborhoods %>%
  left_join(HouseCount_by_neighborhood, by = c("NAME" = "neighborhood"))


HouseCount.Map <- ggplot() + 
  geom_sf(data = neighborhoods, aes(fill = HouseCount)) +
  scale_fill_gradient(low = "#5e3c99", high = "lavender",
                        name = "House Count") +
  labs(title = "Number of Houses Per Neighborhood") +
  mapTheme()

HouseCount.Map
```

By mapping the number observations per neighborhood in our training data, we can confirm if one of the neighborhoods we are predicting poorly for has a low number of observations. However, there are others neighborhoods with closer to the average number of houses that still predict poorly -  other factors are likely causing our poor prediction in specific neighborhoods.

* Note: the color order was reversed from the previous figure to make matching high MAPE, but low number of observation neighborhoods easier to interpret. 

## Mean Absolute Percent Error by Neighborhood Mean Price Scatterplot
```{r mape scatterplot, fig.width = 10}
# Calculate mean price by neighborhood
mean_price_by_neighborhood <- st_drop_geometry(Philly_Data.test) %>%
  group_by(neighborhood) %>%
  summarise(mean_price = mean(sale_price, na.rm = TRUE)) %>%
  ungroup()

# Merge mean_price_by_neighborhood and mean_MAPE_by_neighborhood
neighborhood_summary <- left_join(mean_price_by_neighborhood, mean_MAPE_by_neighborhood, by = "neighborhood")

# Create a scatterplot of MAPE by neighborhood as a function of mean price by neighborhood
scatterplot <- ggplot(neighborhood_summary, aes(x = mean_price, y = mean.MAPE)) +
  geom_point(aes(color = mean.MAPE), size = 1) +
  scale_color_gradient(low = "lavender", high = "#5e3c99") +
  labs(
    title = "Scatterplot of MAPE by Neighborhood as a Function of Mean Price",
    x = "Mean Price by Neighborhood",
    y = "Mean MAPE by Neighborhood",
    color = "MAPE"
  ) +
  theme_minimal()

# Display the scatterplot
print(scatterplot)


```

This plot reinforces our observations from the MAPE map. For most neighborhoods, the average difference between predicted and observed sale price is relatively low, but one neighborhood in particular is a more significant outlier. 

## Model Generalizability by Demographics and Income

```{r tracts, fig.width=10, results = "hide", fig.show='hide'}
tracts20 <- 
  get_acs(geography = "tract", variables = c("B01001_001E","B01001A_001E","B06011_001"), 
          year = 2020, state="PA", county="Philadelphia", geometry=T, output = "wide") %>%
  st_transform(crs=2272)  %>%
  rename(TotalPop = B01001_001E,
         NumberWhites = B01001A_001E,
         Median_Income = B06011_001E) %>%
  mutate(percentWhite = NumberWhites / TotalPop,
         raceContext = ifelse(percentWhite > .5, "Majority White", "Majority Non-White"),
         incomeContext = ifelse(Median_Income > 23200, "High Income", "Low Income"))

```

```{r demo map comp}
grid.arrange(ncol = 2,
  ggplot() + geom_sf(data = na.omit(tracts20), aes(fill = raceContext)) +
    scale_fill_manual(values = c("#FA7800", "#25CB10"), name="Race Context") +
    labs(title = "Race Context") +
    mapTheme() + theme(legend.position="bottom"), 
  ggplot() + geom_sf(data = na.omit(tracts20), aes(fill = incomeContext)) +
    scale_fill_manual(values = c("#25CB10", "#FA7800"), name="Income Context") +
    labs(title = "Income Context") +
    mapTheme() + theme(legend.position="bottom"))
```

To analyze the generalizability of our model, we need to see how it predicts across different contexts. The above maps show American Community Survey data from 2020 for Philadelphia, comparing majority non-white with majority white Census tracts on the left and high income with low income Census tracts on the right. Here, low income is defined as the 2020 30% Area Median Income for a household of two in Philadelphia, as per the Department of Human Services in Pennsylvania.

```{r comptable for demo}
#MAPE for both regressions by race
st_join(Philly_Data.test, tracts20) %>% 
  group_by(raceContext) %>%
  summarize(mean.MAPE = scales::percent(mean(sale_price.APE, na.rm = T))) %>%
  st_drop_geometry() %>%
  na.omit() %>%
  spread(raceContext, mean.MAPE) %>%
  kable(caption = "Test Data MAPE by Neighborhood \nRacial Context") %>% kable_styling(full_width = FALSE)

```

```{r comptable for income}
#MAPE for both regressions by income
st_join(Philly_Data.test, tracts20) %>% 
  filter(!is.na(incomeContext)) %>%
  group_by(incomeContext) %>%
  summarize(mean.MAPE = scales::percent(mean(sale_price.APE, na.rm = T))) %>%
  st_drop_geometry() %>%
  spread(incomeContext, mean.MAPE) %>%
  kable(caption = "Test Data MAPE by Neighborhood \nIncome Context") %>% kable_styling(full_width = FALSE)

```

Adding our test data to the Philly Census tracts allows us to compare the prediction results from our model across the contexts of race and income in the city. These tables show that our model performs with lower accuracy in neighborhoods that have higher proportions of residents of color and lower income residents. 

# Discussion

Ultimately, this model is not effective at predicting home prices. Our predicted sales prices on average were off by about $60,000 compared to the actual sale prices according to our mean absolute error - a mean absolute percent error of around 36%. For most Philadelphia neighborhoods, our errors in the predicted price were relatively low. However, our model show significant inaccuracy in one or a small handful of neighborhoods, which were often lower income, non-white majority neighborhoods. 

Most of the variables used in the model were statistically significant, but certain variables had interesting effects on the home price predictions. HOLC grades, which reflect the racist history of redlining in Philadelphia, show the persistent effects of these problematic lending policies - sale price was predicted to drop by \$6,000 per grade when moving from "Best" (a grade of 1 in this model) to "Hazardous" (a grade of 4). Quality produce and low produce access also show interesting trends that validated our expectations on how they would influence the model - an additional high quality produce store in the area of a home predicted a sale price increase of over \$2,200 and an additional low quality food store nearby is predicted to decrease the price by \$820 . Finally, it was surprising to see the predicted impact of one additional tree within a 500 foot radius - a nearly \$330 increase per tree.

Based on the R-squared value of this model, the model was able to predict about 76% of the variation in home prices. This relatively high R-squared led us to initially believe that our model fit the data well, but we ultimately struggled to account for prices in certain neighborhood contexts, especially in some specific low income and majority non-white. The high R-squared value but poor generalizability highlights the pitfalls in chasing after a high percentage, because in the end, it doesn’t necessarily reflect the predictive quality of the model.

The variables with the largest impact on predicted price were internal characteristics, especially the interior condition of a home, which could drop the predicted price by nearly \$29,000 per condition value - as mentioned previously, a worse assessed condition has a higher value based on the city's methodology. Fireplaces were surprisingly impactful, with the presence of one additional fireplace influencing the predicted price of a home by an increase of over \$23,000. Bathrooms also had a meaningful impact on our predictions, with each additional bathroom worth as much as over \$17,000 in our predictions. The percentage of bachelor's degrees around a home was also influential, with each additional percentage of the population with a bachelor's degree increasing the price prediction by \$830.

While our comparison scatter plot of actual versus predicted sale price appears to show a strong fit, the MAPE map shows how we could often not account for the spatial variation in particular neighborhoods. This could be due to certain neighborhoods having lower numbers of observations to train on. It could also be due to variation in price in these neighborhoods not relating to the variables of our model in the same way as other neighborhoods. Each time we ran the model, one neighborhood in either North Philly or West Philly would be significantly off, and the neighborhoods that the model would fail to predict well for are mostly non-white majority and lower income.

It's possible that in splitting the data between testing and training data sets, some neighborhoods (particularly ones with a lower number of homes) might end up being under-represented in the training data. We also chose to impute values for missing data as the median value for each variable across the whole data set. By doing so, we may be assuming uncommon characteristics for neighborhoods that have more houses with missing data and overestimating the values of homes in that area as a result. Assessment data might also be spatially incomplete, with better data available in wealthier, whiter neighborhoods, which given our methods for imputing missing data would result in skewed imputed values for that neighborhood.

# Conclusion and Recommendation

We do not recommend that Zillow use this model to predict home prices, due to the disparity in prediction accuracy for wealthy and white neighborhoods compared to lower-income neighborhoods and neighborhoods of color. Use of such a model may negatively impact homeowners in these neighborhoods by either underestimating sale price, thereby suppressing the value of their homes and reducing their ability to build generational wealth, or overestimating sale price, resulting in inequitable tax burden in poorer neighborhoods.

This model could be improved through use of automated feature selection, neural nets, and other contemporary approaches to prediction. Short of these changes, the model would benefit from us spending more time refining which independent variables are used in the model and perhaps incorporating more variables that account for fluctuations in price across lower income neighborhoods and predominantly non-white neighborhoods. Additionally, incorporating a variable that accounts for ‘market hotness’ in terms of nearby recent sales could help show the influences of changing market conditions over time.

Additionally, the methods used to impute missing values in the data could be improved by better accounting for spatial variation. For instance, rather than using the median of the entire data set, imputing the value using the median of a house's nearby neighbors or the neighborhood as a whole.

